<!DOCTYPE html>
<style type="text/css">
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<style>
.results-container {
    max-width: 1200px;
    margin: 40px auto;
    background: #ffffff;
    padding: 20px;
    border-radius: 10px;
    box-shadow: 0 8px 20px rgba(0, 0, 0, 0.1);
}

.gallery-box {
    flex: 1;
    background: #f9f9f9;
    padding: 20px;
    border-radius: 10px;
    box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
}

.y-box h3 {
    text-align: center;
    font-size: 1.5rem;
    margin-bottom: 10px;
}

.carousel {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 10px;
}

.carousel img {
    width: 100%;
    border-radius: 10px;
}

.carousel p {
    font-size: 0.9rem;
    text-align: center;
    color: #555;
}
</style>

<style>
    /* Title Shadow */
    .title-shadow {
        text-shadow: 1px 1px 3px rgba(0, 0, 0, 0.2); /* Softer shadow */
        font-weight: bold; /* Ensure the title is bold */
        font-size: 3rem; /* Slightly larger font for emphasis */
        font-family: 'Arial', sans-serif; /* Consistent font */
        color: #333; /* Darker gray for softer appearance */
    }

    /* Button Styles */
    .custom-button {
        display: inline-block;
        background-color: #000; /* Black color */
        color: white; /* White text */
        font-family: 'Arial', sans-serif;
        font-size: 1rem;
        padding: 10px 20px;
        border: none;
        border-radius: 25px; /* Rounded corners */
        cursor: pointer;
        text-decoration: none; /* Remove underline for links */
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15); /* Enhanced shadow */
        transition: all 0.3s ease; /* Smooth hover effect */
    }

    .custom-button:hover {
	    background-color: #eee;  /* White background */
	    color: #000;             /* Black text */
	    box-shadow: 0 6px 12px rgba(0, 0, 0, 0.25);
	    transform: scale(1.05);  /* “Expand and float” effect remains */
    }

    .button-container {
        display: flex;
        justify-content: center; /* Center buttons horizontally */
        gap: 18px; /* Increased space between buttons */
        margin-top: 20px; /* Space above the buttons */
    }

    .panel-style {
            background-color: #fafafa;
            padding: 20px;
            margin: 20px auto;
            border: 1px solid #ccc;
            border-radius: 8px;
        }
</style>

<style>
  .title-box {
    border: 2px solid #333;         /* Solid border */
    background-color: #f9f9f9;      /* Light background */
    padding: 20px;                  /* Spacing around the title */
    margin: 20px auto;              /* Center horizontally + top/bottom spacing */
    border-radius: 10px;            /* Rounded corners */
    max-width: 800px;               /* Optional, keeps box from being too wide */
    text-align: center;             /* Center the title text */
  }
</style>


<style>
  .abstract-container {
    max-width: 800px; /* Set the maximum width for the block */
    margin: 0 auto; /* Center the block horizontally */
    background-color: #f5f5f5; /* Light gray background */
    padding: 20px; /* Add padding inside the block */
    border-radius: 10px; /* Rounded corners */
    box-shadow: 0 8px 15px rgba(0, 0, 0, 0.2); /* Increase shadow intensity */
    text-align: justify; /* Align text for better readability */
  }

  .abstract-container h2 {
    text-align: center; /* Center the Abstract heading */
    font-weight: bold; /* Make the heading bold */
    font-size: 2rem; /* Increase font size for the heading */
    margin-bottom: 15px; /* Add spacing below the heading */
  }
</style>

<style>
    /* Audio Section Styling */
    .audio-section {
        max-width: 600px; /* Limit the width */
        margin: 30px auto; /* Center align */
        background-color: #f9f9f9; /* Light background */
        padding: 20px; /* Add padding inside the section */
        border-radius: 10px; /* Rounded corners */
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); /* Subtle shadow */
        text-align: center; /* Center align text and content */
    }

    /* Audio Player Styling */
    .audio-section audio {
        width: 100%; /* Make the audio player responsive */
        border-radius: 5px; /* Slightly rounded corners for the audio player */
        outline: none; /* Remove default focus outline */
    }

    /* Caption Styling */
    .audio-caption {
        font-family: 'Arial', sans-serif; /* Consistent font */
        font-size: 1rem; /* Standard font size */
        color: #666; /* Subtle text color */
        margin-top: 15px; /* Add spacing above the caption */
        display: flex; /* Flexbox for alignment */
        align-items: center; /* Center vertically */
        justify-content: center; /* Center horizontally */
        gap: 10px; /* Space between icon and text */
    }

    .audio-caption i {
        font-size: 1.2rem; /* Slightly larger icon */
        color: #007bff; /* Blue color for the icon */
    }
</style>

<style>
  .bibtex-block {
    background: #0f172a;
    color: #e2e8f0;
    padding: 1rem 1.25rem;
    border-radius: 12px;
    overflow-x: auto;
    margin: 0; /* Remove margin space */
    line-height: 1.4;
    white-space: pre-wrap; /* Wrap text if needed */
  }

  .bibtex-wrap {
    position: relative;
    display: inline-block;
  }

  .bibtex-wrap pre {
    padding-bottom: 0.75rem; /* slightly less padding to avoid large empty space */
  }

  .copy-btn {
    position: absolute;
    top: 8px;
    right: 12px;
    background: rgba(255,255,255,0.15);
    border: 1px solid rgba(255,255,255,0.4);
    color: rgba(255,255,255,0.85);
    padding: 0.25rem 0.65rem;
    border-radius: 4px;
    font-size: 0.75rem;
    cursor: pointer;
    line-height: 1.2;
    transition: all 0.15s ease;
  }

  .copy-btn:hover,
  .copy-btn:focus {
    background: rgba(255,255,255,0.25);
    color: #fff;
  }
</style>

<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriately as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="NRMF"/>
  <meta property="og:description" content="Geometric Neural Distance Fields for Learning Human Motion Priors"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="NRMF">
  <meta name="twitter:description" content="Geometric Neural Distance Fields for Learning Human Motion Priors">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>NRMF</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;800&display=swap" rel="stylesheet">


  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- Custom Style for Font Change -->
  <!-- <style>
    body, h1, h2, h3, h4, h5, h6, p, span, a {
        font-family: Arial, sans-serif !important; /* Apply Arial globally */
    }
  </style> -->
  <style>
    /* Light blue page background */
    body {
      background: linear-gradient(180deg, #f8fafc 0%, #eef2f7 100%);
    }
  
    /* Use Inter only for the top hero: title, authors, and buttons */
    .hero .publication-title,
    .hero .publication-authors,
    .hero .button-container .custom-button {
      font-family: Inter, system-ui, Arial, sans-serif !important;
    }
  
    /* Title weight/metrics to match the screenshot feel */
    .hero .publication-title {
      font-weight: 800;          /* Bold, crisp */
      line-height: 1.15;
      letter-spacing: .2px;
      text-shadow: 0 1px 0 rgba(255,255,255,.6); /* subtle lift */
    }
  
    /* Slightly stronger authors line for readability */
    /* .hero .publication-authors {
      font-weight: 600;
    } */
  
    /* Buttons: keep your style, just ensure Inter weight shows nicely */
    .hero .button-container .custom-button {
      font-weight: 700;
    }
  </style>

  <!-- <style>
    :root{
      --bibx-surface:#fff;
      --bibx-ring:rgba(0,0,0,.07);
      --bibx-shadow:0 12px 28px rgba(0,0,0,.08);
      --bibx-shadow-hover:0 16px 36px rgba(0,0,0,.12);
      --bibx-success:#22c55e;
      --bibx-radius:18px;
    }

    .bibx-card{
      background:#fff;              /* was var(--bibx-surface) */
      border:1px solid rgba(0,0,0,.07);
      border-radius:18px;
      box-shadow:0 12px 28px rgba(0,0,0,.08);
      padding:20px 18px 10px 18px;
      transition:box-shadow .2s ease, transform .2s ease, border-color .2s ease;
    }
    .bibx-card:hover{ box-shadow:var(--bibx-shadow-hover); transform:translateY(-1px); border-color:rgba(0,0,0,.12); }

    .bibx-pre{
      background:#fff;              /* was #f6f7f9 */
      border:1px solid rgba(0,0,0,.05);
      border-radius:12px;
      margin:0;
      padding:18px 16px;
      overflow:auto;
      line-height:1.75;
      font-size:15px;
      color:#1f2937;
      font-family:ui-monospace,SFMono-Regular,Menlo,Consolas,Monaco,monospace;
    }
  </style> -->

  <style>
    /* BibTeX card + button */
    .bibx-card{
      position:relative;
      background:#fff;
      border:1px solid rgba(0,0,0,.07);
      border-radius:18px;
      box-shadow:0 12px 28px rgba(0,0,0,.08);
      padding:20px 18px 10px 18px;
      transition:box-shadow .2s ease, transform .2s ease, border-color .2s ease;
    }
    .bibx-card:hover{
      box-shadow:0 16px 36px rgba(0,0,0,.12);
      transform:translateY(-1px);
      border-color:rgba(0,0,0,.12);
    }

    .bibx-pre{
      margin: 0;
      padding: 20px;                 /* keep some breathing room */
      background: transparent !important;
      border: 0 !important;
      border-radius: 0;
      overflow: auto;
      line-height: 1.75;
      font-size: 15px;
      color: #1f2937;
      font-family: ui-monospace,SFMono-Regular,Menlo,Consolas,Monaco,monospace;
    }

    /* Tiny toast that says “Copied!” */
    .bibx-toast{
      position: absolute;
      top: 12px;
      right: 56px;                   /* sits left of the button */
      background: #111;              /* dark chip */
      color: #fff;
      padding: 6px 8px;
      border-radius: 8px;
      font-size: 12px;
      line-height: 1;
      opacity: 0;
      transform: translateY(-4px);
      pointer-events: none;
      transition: opacity .2s ease, transform .2s ease;
    }
    .bibx-toast.show{
      opacity: 1;
      transform: translateY(0);
    }
    .bibx-toast::after{
      content: "";
      position: absolute;
      top: 50%;
      right: -6px;
      transform: translateY(-50%);
      border: 6px solid transparent;
      border-left-color: #111;       /* little arrow toward button */
    }

    .bibx-copy{
      position:absolute; top:10px; right:12px;
      width:36px; height:36px; display:grid; place-items:center;
      border-radius:999px; border:1px solid rgba(0,0,0,.14);
      background:#ffffff; cursor:pointer; z-index:5; pointer-events:auto;
      box-shadow:0 4px 10px rgba(0,0,0,.10);
      transition:transform .15s ease, box-shadow .15s ease, background .15s ease, border-color .15s ease;
    }
    .bibx-card:hover .bibx-copy{ box-shadow:0 6px 16px rgba(0,0,0,.14); }
    .bibx-copy:focus-visible{ outline:2px solid #93B3E5; outline-offset:2px; }

    .bibx-clip, .bibx-check{ fill:#0f172a; opacity:.95; }
    .bibx-check{ display:none; }

    @keyframes bibx-spin{ to{ transform:rotate(360deg); } }
    .bibx-copy.spinning .bibx-clip{ animation:bibx-spin .6s linear; }

    .bibx-copy.copied{
      background:#ecfdf5; border-color:rgba(34,197,94,.45);
      box-shadow:0 6px 16px rgba(34,197,94,.18);
    }
    .bibx-copy.copied .bibx-clip{ display:none; }
    .bibx-copy.copied .bibx-check{ display:block; fill:#22c55e; }
  </style>

  <script>
    // Supports multiple BibTeX cards if you add more later
    (function(){
      document.querySelectorAll('.bibx-card').forEach(card=>{
        const btn  = card.querySelector('.bibx-copy');
        const code = card.querySelector('code');
        if(!btn || !code) return;

        btn.addEventListener('click', async ()=>{
          const text = code.innerText.trim();
          btn.classList.add('spinning');

          try {
            await navigator.clipboard.writeText(text);
          } catch (e) {
            // fallback
            const ta = document.createElement('textarea');
            ta.value = text;
            document.body.appendChild(ta);
            ta.select();
            document.execCommand('copy');
            document.body.removeChild(ta);
          }

          setTimeout(()=>{
            btn.classList.remove('spinning');
            btn.classList.add('copied');
          }, 250);

          setTimeout(()=>{
            btn.classList.remove('copied');
          }, 1600);
        });
      });
    })();
  </script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>

<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <!-- Title Section -->
                    <h1 class="title is-1 publication-title title-shadow">
                        Geometric Neural Distance Fields for Learning Human Motion Priors
                    </h1>
                		<!-- <div class="is-size-5" style="color: rgb(0, 0, 0); font-weight: bold; margin-top: 5px;">
                          arXiv 2025
                    </div> -->
                    <div class="is-size-5 publication-authors">
                      <!-- Line 1 -->
                      <div>
                        <span class="author-block"><a href="https://zhengdiyu.github.io/" target="_blank">Zhengdi Yu</a><sup>1</sup>,</span>
                        <span class="author-block"><a href="https://www.simofoti.com/" target="_blank">Simone Foti</a><sup>1</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=C7DtSzYAAAAJ&hl=en" target="_blank">Linguang Zhang</a><sup>2</sup>,</span>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=GzX462kAAAAJ&hl=en" target="_blank">Amy Zhao</a><sup>2</sup>,</span>
                      </div>
                    
                      <!-- Line 2 -->
                      <div>
                        <span class="author-block"><a href="https://scholar.google.com/citations?user=9HoiYnYAAAAJ&hl=en" target="_blank">Cem Keskin</a><sup>2</sup>,</span>
                        <span class="author-block"><a href="https://profiles.imperial.ac.uk/s.zafeiriou/" target="_blank">Stefanos Zafeiriou</a><sup>1</sup>,</span>
                        <span class="author-block"><a href="https://tolgabirdal.github.io/" target="_blank">Tolga Birdal</a><sup>1</sup></span>
                      </div>
                    </div>
                    <div class="is-size-5 publication-authors">
                         <sup>1</sup>Imperial College London&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>2</sup>Meta Reality Labs
                    </div>

                    <!-- Buttons Section -->
                    <div class="button-container">
                        <!-- Paper Button -->
                        <a href="https://arxiv.org/pdf/2509.09667" target="_blank" class="custom-button">
                            <i class="fas fa-file-pdf"></i> Paper
                        </a>

                        <!-- Code Button -->
                        <a href="https://github.com/ZhengdiYu/NRMF" target="_blank" class="custom-button">
                            <i class="fab fa-github"></i> Code
                        </a>

                        <!-- ArXiv Button -->
                        <a href="https://arxiv.org/abs/2509.09667" target="_blank" class="custom-button">
                            <i class="ai ai-arxiv"></i> arXiv
                        </a>

                        <!-- Video Button -->
                        <a href="https://youtu.be/jbW68A2aYWs" target="_blank" class="custom-button">
                            <i class="fas fa-video"></i> Video
                        </a>

                        <!-- Poster Button -->
                        <a href="static/pdfs/nrmf.pdf" target="_blank" class="custom-button">
                            <i class="fas fa-image"></i> Poster
                        </a>
                    </div>

                    <!-- Abstract Section Combined with AI-generated Voice -->
                    <div class="abstract-container" style="margin-top: 30px;">
                        <!-- Abstract -->
                        <h2>Abstract</h2>
                        <p>
                            We introduce <strong><span style="color:#93b3e5;">Neural Riemannian Motion Fields (NRMF)</span></strong>, a novel 3D generative human motion prior that enables robust, temporally consistent, and physically plausible 3D motion recovery. Unlike existing VAE or diffusion-based methods, our higher-order motion prior explicitly models the human motion in the zero level set of a collection of neural distance fields (NDFs) corresponding to pose, transition (velocity), and acceleration dynamics. Our framework is rigorous in the sense that our NDFs are constructed on the product space of joint rotations, their angular velocities, and angular accelerations, respecting the geometry of the underlying articulations. We further introduce: (i) a novel adaptive-step hybrid algorithm for projecting onto the set of plausible motions, and (ii) a novel geometric integrator to "roll out" realistic motion trajectories during test-time-optimization and generation. Our experiments show significant and consistent gains: trained on the AMASS dataset, NRMF remarkably generalizes across multiple input modalities and to diverse tasks ranging from denoising to motion in-betweening and fitting to partial 2D / 3D observations.
                        </p>

                        <!-- AI-generated Voice Section -->
                        <!-- <hr style="margin: 20px 0; border: none; border-top: 1px solid #ddd;"> -->
                        <audio controls style="width: 100%; border-radius: 5px;">
                            <source src="static/audio/ai_generated_intro.wav" type="audio/mpeg">
                            Your browser does not support the audio element.
                        </audio>
                        <p style="font-family: 'Arial', sans-serif; font-size: 0.9rem; color: #666; font-weight: bold; text-align: center; margin-top: 10px;">
                            <i class="fas fa-microphone-alt" style="font-size: 1rem; color: #007bff; margin-right: 5px;"></i>
                            AI-generated Podcast (Paper Introduction)
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/global.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column">
        <div class="content">
           <video id="matting-video" autoplay controls muted loop playsinline height="100%">
             <source src="static/videos/wild.mp4"
                     type="video/mp4">
           </video>
         </div>
       </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Abstract Section Combined with AI-generated Voice -->
<!-- <section class="section">
<div class="abstract-container">
    <h2>Abstract</h2>
    <p>
        We introduce <strong><span style="color:#93B3E5;">Neural Riemannian Motion Fields (NRMF)</span></strong>, a novel 3D generative human motion prior that enables robust, temporally consistent, and physically plausible 3D motion recovery. Unlike existing VAE or diffusion-based methods, our higher-order motion prior explicitly models the human motion in the zero level set of a collection of neural distance fields (NDFs) corresponding to pose, transition (velocity), and acceleration dynamics. Our framework is rigorous in the sense that our NDFs are constructed on the product space of joint rotations, their angular velocities, and angular accelerations, respecting the geometry of the underlying articulations. We further introduce: (i) a novel adaptive-step hybrid algorithm for projecting onto the set of plausible motions, and (ii) a novel geometric integrator to “roll out” realistic motion trajectories during test-time-optimization and generation. Our experiments show significant and consistent gains: trained on the AMASS dataset, NRMF remarkably generalizes across multiple input modalities and to diverse tasks ranging from denoising to motion in-betweening and fitting to partial 2D / 3D observations.
    </p>

    <audio controls style="width: 100%; border-radius: 5px;">
        <source src="static/audio/ai_generated_intro.wav" type="audio/mpeg">
        Your browser does not support the audio element.
    </audio>
    <p style="font-family: 'Arial', sans-serif; font-size: 0.9rem; color: #666; font-weight: bold; text-align: center; margin-top: 10px;">
        <i class="fas fa-microphone-alt" style="font-size: 1rem; color: #007bff; margin-right: 5px;"></i>
        AI-generated Podcast (Paper Introduction)
    </p>
</div>
</section> -->
	
<!-- Video Section -->
<div class="video-section" style="max-width: 800px; margin: 40px auto; text-align: center;">
    <video controls style="width: 100%; border-radius: 10px; aspect-ratio: 16 / 9;">
        <source src="static/videos/presentation.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </video>
    <!-- <p style="font-family: 'Arial', sans-serif; font-size: 1.2rem; color: #444; font-weight: bold; margin-top: 15px;">
        Video Presentation
    </p> -->
</div>

<!-- Method Overview Section -->
<div class="method-container" style="max-width: 800px; margin: 40px auto; background: #ffffff; padding: 20px; border-radius: 10px; box-shadow: 0 8px 20px rgba(0, 0, 0, 0.1);">
    <!-- Image in Method Overview -->
    <h2 style="text-align: center; font-size: 2rem; font-weight: bold;">Method Overview</h2>
    <p style="text-align: justify;">
          <strong><span style="color:#93B3E5;">NRMF</span></strong> is a general-purpose, expressive and robust unconditional motion prior. 
  It models the space of plausible <strong>poses</strong> (\(\theta\)), 
  <strong>transitions</strong> (\(\dot{\theta}\)), and 
  <strong>accelerations</strong> (\(\ddot{\theta}\)) on the zero-level set of a 
  <strong>geometric neural distance field</strong>. 
  This implicitly captures the data distribution. 
  Poses are depicted alongside their transitions and accelerations, which are visualized as blue dots 
  onto the per-joint distributions of learned transitions and as blue rings around the magnitude distribution 
  of all accelerations.
    </p>
    <div style="text-align: center; margin-top: 20px;">
        <img src="static/images/overview.png" alt="Method Overview Diagram" style="width: 100%; max-width: 700px; border-radius: 10px;">
    </div>

    <p style="text-align: justify;">
        We develop projection (\(\Pi\)) and integration algorithms to deploy <strong>NRMF</strong> into several applications as shown: (<strong>i</strong>) motion denoising from noisy observations, (<strong>ii</strong>) motion estimation on in-the-wild videos, (<strong>iii</strong>) motion in-betweening, and (<strong>iv</strong>) motion generation.
    </p>

    <!-- Image in Method Overview -->
    <div style="text-align: center; margin-top: 20px;">
        <img src="static/images/app.png" alt="Method Overview Diagram" style="width: 100%; max-width: 700px; border-radius: 10px;">
    </div>

    <p style="text-align: justify;">
      <strong><span style="color:#93B3E5;">NRMF</span></strong> learns to represent the space of realistic human motion by modeling the 
      <em>zero-level sets</em> of three distinct yet related neural distance fields over {\(\theta\), \(\dot{\theta}\), \(\ddot{\theta}\)}. 
      Each component is trained to predict the distance to the manifold of plausible motion states using motion capture data. 
      The <strong>pose field</strong> learns which joint configurations are human-like, the <strong>transition field</strong> captures temporal consistency across frames, 
      and the <strong>acceleration field</strong> enforces second-order realism by modeling smooth and plausible dynamics. 
      These fields enable projection-based inference and allow NRMF to robustly reconstruct temporally consistent and physically plausible motion.
    </p>
    
    <!-- Image in Method Overview -->
    <div style="text-align: center; margin-top: 20px;">
      <img src="static/images/method.png" alt="Method Overview Diagram" style="width: 100%; max-width: 700px; border-radius: 10px;">
  </div>
</div>


<h2 class="title is-3 has-text-centered">Applications</h2>
<hr>
<section id="video_4d" class="section dynamic-section">
  <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
          <div class="column is-full  panel-style">
                <h3 class="title is-3"><strong><span style="color:#93B3E5;">Motion Denoising & Infilling from Noisy Observations</span></strong></h3>
               <p>
                   Our method can recover the clean and plausible motion from noisy 3D observations as <strong><span style="color:#93B3E5;">input</span></strong>, as well as infilling the <strong><span style="color:rgb(109, 3, 109);">missing motion</span></strong> of body parts and in-betweening the motion. Gaussian noise is added to the 3D observations to simulate the noisy observations.
               </p>
               <div id="wrapper" style="
         display: flex;
         flex-wrap: nowrap;
         justify-content: center;
         align-items: center;
         gap: 2em;
         margin-top: 20px;
       ">
                   <div class="video-container">
                       <video autoplay muted loop style="width: 100%;">
                           <source src="static/videos/noisy_fixed.mp4" type="video/mp4">
                           Your browser does not support the video tag.
                       </video>
                       <div style="display: flex; justify-content: space-between; margin-top: 6px; font-family: 'Arial', sans-serif; font-size: 1rem; font-weight: bold;">
                         <span style="color:#93B3E5; text-align:center; flex:1;">Noisy Input</span>
                         <span style="color:rgb(0, 0, 0); text-align:center; flex:1;">Output</span>
                       </div>
                   </div>
                   <div class="video-container">
                       <video autoplay muted loop style="width: 100%;">
                           <source src="static/videos/part_fixed.mp4" type="video/mp4">
                           Your browser does not support the video tag.
                       </video>
                       <div style="display: flex; justify-content: space-between; margin-top: 6px; font-family: 'Arial', sans-serif; font-size: 1rem; font-weight: bold;">
                        <span style="color:#000000; text-align:center; flex:1;">Partial Input</span>
                        <span style="color:rgb(109, 3, 109); text-align:center; flex:1;">Output</span>
                       </div>
                   </div>
               </div>
              <!-- <p style="font-family: 'Arial', sans-serif; font-size: 1rem; color: #444; font-weight: bold; margin-top: 20px; text-align: center;"> -->
                <p style="font-size: 1rem; color: #444; margin-top: 20px; text-align: center;"></p>
                Even under the challenging conditions of <strong><span style="color:rgb(109, 3, 109);">partial</span></strong> + <strong><span style="color:#93B3E5;">noisy</span></strong> observations, NRMF can still recover clean and plausible motion.
              </p>
         <div id="wrapper" style="
         display: flex;
         flex-wrap: nowrap;
         justify-content: center;
         align-items: center;
         gap: 2em;
         margin-top: 20px;
       ">
                   <div class="video-container">
                       <video autoplay muted loop style="width: 100%; aspect-ratio: 22 / 3;">
                           <source src="static/videos/partnoisy.mp4" type="video/mp4">
                           Your browser does not support the video tag.
                       </video>
                       <div style="display: flex; justify-content: space-between; margin-top: 6px; font-family: 'Arial', sans-serif; font-size: 1rem; font-weight: bold;">
                        <span style="color:#000000; text-align:center; flex:1;">Input</span>
                        <span style="color:rgb(0, 0, 0); text-align:center; flex:1;">Ground Truth</span>
                        <span style="color:rgb(0, 0, 0); text-align:center; flex:1;">Ours</span>
                        <span style="color:rgb(0, 0, 0); text-align:center; flex:1;">RoHM</span>
                       </div>
                   </div>
               </div>
            </div>
      </div>
  </div>
</section>

<!-- Wild -->
<section id="video_4d" class="section dynamic-section">
  <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
          <div class="column is-full  panel-style">
                             <h3 class="title is-3"><strong><span style="color:#93B3E5;">Motion Estimation on In-the-wild Videos</span></strong></h3>
               <p>
                   Our method can recover clean and plausible motion with in-the-wild RGB-D observations as input.
               </p>
               <div id="wrapper" style="
         display: flex;
         flex-wrap: nowrap;
         justify-content: center;
         align-items: center;
         gap: 2em;
         margin-top: 20px;
       ">
                   <div class="video-container">
                       <video autoplay muted loop style="width: 100%; aspect-ratio: 16 / 9;">
                           <source src="static/videos/wild.mp4" type="video/mp4">
                           Your browser does not support the video tag.
                       </video>
                       <p style="font-family: 'Arial', sans-serif; font-size: 1rem; color: #444; font-weight: bold; margin-top: 10px; text-align: center;">
                           Results on PROX, EgoBody, 3DPW and in-the-wild videos.
                       </p>
                   </div>
                   <!-- <div class="video-container">
                       <video controls style="width: 100%; border-radius: 10px; aspect-ratio: 16 / 9;">
                           <source src="static/videos/2_compress.mp4" type="video/mp4">
                           Your browser does not support the video tag.
                       </video>
                       <p style="font-family: 'Arial', sans-serif; font-size: 1rem; color: #444; font-weight: bold; margin-top: 10px; text-align: center;">
                           Denoised Output
                       </p>
                   </div> -->
               </div>
              <!-- <p> See more dynamic reconstruction results on DAVIS dataset in our <a href="./gallery.html">gallery</a>.</p> -->
          </div>
      </div>
  </div>
</section>


<section id="video_4d" class="section dynamic-section">
  <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
          <div class="column is-full  panel-style">
                             <h3 class="title is-3"><strong><span style="color:#93B3E5;">Motion In-betweening and Generation</span></strong></h3>
               <p>
                   Our method can in-between <strong><span style="color:#93B3E5;">plausible motion</span></strong> from only <strong><span style="color:rgb(109, 3, 109);">partially given keyframes</span></strong> as input, as well as generate the natural motion from initial poses, while keeping temporally consistent and physically plausible.
               </p>
               <div id="wrapper" style="
         display: flex;
         flex-wrap: nowrap;
         justify-content: center;
         align-items: center;
         gap: 2em;
         margin-top: 20px;
       ">
                   <div class="video-container">
                       <video autoplay muted loop style="width: 100%; aspect-ratio: 16 / 9;">
                           <source src="static/videos/between.mp4" type="video/mp4">
                           Your browser does not support the video tag.
                       </video>
                       <p style="font-family: 'Arial', sans-serif; font-size: 1rem; color: #444; font-weight: bold; margin-top: 10px; text-align: center;">
                           In-betweening on <strong><span style="color:rgb(109, 3, 109);">partial</span></strong> keyframes.
                       </p>
                   </div>
                   <div class="video-container">
                       <video autoplay muted loop style="width: 100%; aspect-ratio: 16 / 9;">
                           <source src="static/videos/generation.mp4" type="video/mp4">
                           Your browser does not support the video tag.
                       </video>
                       <p style="font-family: 'Arial', sans-serif; font-size: 1rem; color: #444; font-weight: bold; margin-top: 10px; text-align: center;">
                           Generation from (common standing pose)
                       </p>
                   </div>
               </div>
              <!-- <p> See more dynamic reconstruction results on DAVIS dataset in our <a href="./gallery.html">gallery</a>.</p> -->
          </div>
      </div>
  </div>
</section>

<!-- Poster -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <!-- Title -->
          <h2 class="title is-3" style="font-size: 32px; text-align: center;">Poster</h2>
          <!-- Content -->
          <div class="column">
            <div class="content">
              <div class="poster-static-content">
                <!-- Replace the video with an image or screenshot -->
                <img src="static/images/nrmf.png" alt="Presentation Poster">
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Poster -->

<!--
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
	  <h2 class="title is-3">Presentation Video</h2>
           <div class="column">
             <div class="content">
               <div class="publication-video">
               <iframe width="560" height="315" src="https://www.youtube.com/embed/-HTr_-DLqCg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
             </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
-->
	
<section class="hero is-small" style="background-color: transparent;">
  <div class="hero-body">
    <div class="container">
      <!-- Title: centered and slightly larger -->
      <h2 class="title is-3 has-text-centered">Miscellaneous</h2>
      <hr>

      <!-- Box with a custom gray background color -->
      <div class="box" style="background-color: #f4f4f4;">
        <div class="columns is-vcentered is-multiline">
          <div class="column is-one-third has-text-centered">
            <!-- Paper image -->
            <figure class="image is-inline-block" style="max-width: 200px; margin: 0 auto;">
              <a href="https://arxiv.org/pdf/2509.09667.pdf" target="_blank">
                <img
                  class="layered-paper-big"
                  src="static/images/paper.png"
                  alt="Paper cover image"
                  style="width:100%; border-radius: 5px;"
                />
              </a>
            </figure>
          </div>

          <div class="column is-two-thirds">
            <!-- Paper details -->
            <p style="font-size:1rem; line-height:1.4;">
              <b>Geometric Neural Distance Fields for Learning Human Motion Priors</b><br>
              <span>Zhengdi Yu, Simone Foti, Linguang Zhang, Amy Zhao, Cem Keskin, Stefanos Zafeiriou, Tolga Birdal</span><br>
              <span>arXiv 2025</span>
            </p>

            <!-- Button to PDF (optional) -->
            <a href="https://arxiv.org/pdf/2509.09667" class="button is-link" target="_blank">
              <span class="icon"><i class="fas fa-file-pdf"></i></span>
              <span>View PDF</span>
            </a>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ===== BibTeX with EXACT-style Copy button ===== -->
<section class="section" id="BibTeX">
  <!-- <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>

    <div class="bibtex-wrap">
      <pre id="bibtexEntry" class="bibtex-block">@article{yu2025nrmf,
        title = {Geometric Neural Distance Fields for Learning Human Motion Priors},
        author = {Yu, Zhengdi and Foti, Simone and Zhang, Linguang and Zhao, Amy and Keskin, Cem and Zafeiriou, Stefanos and Birdal, Tolga},
        journal = {arXiv preprint arXiv:2509.09667},
        year = {2025}
      }</pre>      
      <button id="copyBibtex" class="copy-btn">Copy</button>
    </div>
  </div>
</section> -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop">
    <h2 class="title">Bibtex</h2>

    <div class="bibx-card">
      <button class="bibx-copy" aria-label="Copy BibTeX" title="Copy BibTeX">
        <!-- clipboard -->
        <svg class="bibx-clip" viewBox="0 0 24 24" width="20" height="20" aria-hidden="true">
          <path d="M16 4h-1.18A3 3 0 0 0 12 2a3 3 0 0 0-2.82 2H8a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h8a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2Zm-4-1a1 1 0 0 1 1 1h-2a1 1 0 0 1 1-1Zm4 17H8V6h1.18A3 3 0 0 0 12 8a3 3 0 0 0 2.82-2H16v14Z"/>
        </svg>
        <!-- check -->
        <svg class="bibx-check" viewBox="0 0 24 24" width="20" height="20" aria-hidden="true">
          <path d="M9 16.2 4.8 12l-1.4 1.4L9 19 21 7l-1.4-1.4Z"/>
        </svg>
      </button>

      <span class="bibx-toast" aria-live="polite" aria-atomic="true">Copied!</span>
      <pre class="bibx-pre"><code>@article{yu2025nrmf,
  title   = {Geometric Neural Distance Fields for Learning Human Motion Priors},
  author  = {Yu, Zhengdi and Foti, Simone and Zhang, Linguang and Zhao, Amy and Keskin, Cem and Zafeiriou, Stefanos and Birdal, Tolga},
  journal = {arXiv preprint arXiv:2509.09667},
  year    = {2025}
}</code></pre>
    </div>
  </div>
</section>


<!--End BibTex citation -->

<!--BibTex citation -->
<section class="section" id="acknowledgements" style="padding-top: 1.5rem; padding-bottom: 1.5rem; margin-bottom: 0;">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <p>We thank the authors of the following works for providing their valuable code and data:</p>
    <p>
      <a href="https://github.com/hynann/NRDF" target="_blank">NRDF</a>: Neural Riemannian Distance Fields for Learning Articulated Pose Priors<br>
      <a href="https://github.com/davrempe/humor" target="_blank">HuMoR</a>: HuMoR:3D Human Motion Model for Robust Pose Estimation<br>
      <a href="https://github.com/c-he/NeMF/" target="_blank">NeMF</a>: Neural Motion Fields for Kinematic Animation<br>
      <a href="https://github.com/garvita-tiwari/PoseNDF/tree/version2" target="_blank">PoseNDF</a>: Modeling Human Pose Manifolds with Neural Distance Fields
    </p>
  </div>
</section>
<!--End BibTex citation -->

<!-- Contact Section -->
<section class="section" id="contact" style="padding-top: 1.2rem;">
  <div class="container is-max-desktop content">
    <h2 class="title">Contact</h2>
    <p>
      Please contact 
      <a href="mailto:z.yu23@imperial.ac.uk">z.yu23@imperial.ac.uk</a> 
      or 
      <a href="mailto:ZhengdiYu@hotmail.com">ZhengdiYu@hotmail.com</a>
      for any inquiries related to this work.
    </p>
  </div>
</section>
<!-- End Contact -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

	  <p>
	       This page was inspired by the <a href="https://nerfies.github.io/" target="_blank">Nerfies website</a>.
	  </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Copy-to-clipboard (works without permissions) -->
<script>
  (function(){
    const btn = document.getElementById('copyBibtex');
    const pre = document.getElementById('bibtexEntry');
    if (btn && pre) {
      btn.addEventListener('click', async () => {
        const text = pre.innerText.trim();
        try {
          await navigator.clipboard.writeText(text);
        } catch(e) {
          const ta = document.createElement('textarea');
          ta.value = text; document.body.appendChild(ta);
          ta.select(); document.execCommand('copy'); document.body.removeChild(ta);
        }
        const old = btn.textContent;
        btn.textContent = 'Copied!';
        setTimeout(()=> btn.textContent = old, 1400);
      });
    }
  })();
</script>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

<script>
  // Delegated click so it survives re-renders
  document.addEventListener('click', async (e) => {
  const btn = e.target.closest('.bibx-copy');
  if (!btn) return;

  const card = btn.closest('.bibx-card');
  const code = card?.querySelector('code');
  if (!code) return;

  const text = code.innerText.trim();
  btn.classList.add('spinning');

  try {
    await navigator.clipboard.writeText(text);
  } catch {
    const ta = document.createElement('textarea');
    ta.value = text; document.body.appendChild(ta);
    ta.select(); document.execCommand('copy'); ta.remove();
  }

  setTimeout(() => {
    btn.classList.remove('spinning');
    btn.classList.add('copied');

    // Show the Copied! toast
    const toast = card.querySelector('.bibx-toast');
    if (toast){
      toast.classList.add('show');
      // optional: customize message
      // toast.textContent = 'Copied!';
      setTimeout(() => toast.classList.remove('show'), 1200);
    }
  }, 250);

  setTimeout(() => btn.classList.remove('copied'), 1600);
});

</script>
  </body>
  </html>
